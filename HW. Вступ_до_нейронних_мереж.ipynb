{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lbLHTNfSclli"
   },
   "source": [
    "**Секція 1. Логістична регресія з нуля.**\n",
    "\n",
    "Будемо крок за кроком будувати модель лог регресії з нуля для передбачення, чи буде врожай більше за 80 яблук (задача подібна до лекційної, але на класифікацію).\n",
    "\n",
    "Давайте нагадаємо основні формули для логістичної регресії.\n",
    "\n",
    "### Функція гіпотези - обчислення передбачення у логістичній регресії:\n",
    "\n",
    "$$\n",
    "\\hat{y} = \\sigma(x W^T + b) = \\frac{1}{1 + e^{-(x W^T + b)}}\n",
    "$$\n",
    "\n",
    "Де:\n",
    "- $ \\hat{y} $ — це ймовірність \"позитивного\" класу.\n",
    "- $ x $ — це вектор (або матриця для набору прикладів) вхідних даних.\n",
    "- $ W $ — це вектор (або матриця) вагових коефіцієнтів моделі.\n",
    "- $ b $ — це зміщення (bias).\n",
    "- $ \\sigma(z) $ — це сигмоїдна функція активації.\n",
    "\n",
    "### Як обчислюється сигмоїдна функція:\n",
    "\n",
    "Сигмоїдна функція $ \\sigma(z) $ має вигляд:\n",
    "\n",
    "$$\n",
    "\\sigma(z) = \\frac{1}{1 + e^{-z}}\n",
    "$$\n",
    "\n",
    "Ця функція перетворює будь-яке дійсне значення $ z $ в інтервал від 0 до 1, що дозволяє інтерпретувати вихід як ймовірність для логістичної регресії.\n",
    "\n",
    "### Формула функції втрат для логістичної регресії (бінарна крос-ентропія):\n",
    "\n",
    "Функція втрат крос-ентропії оцінює, наскільки добре модель передбачає класи, порівнюючи передбачені ймовірності $ \\hat{y} $ із справжніми мітками $ y $. Формула наступна:\n",
    "\n",
    "$$\n",
    "L(y, \\hat{y}) = - \\left[ y \\cdot \\log(\\hat{y}) + (1 - y) \\cdot \\log(1 - \\hat{y}) \\right]\n",
    "$$\n",
    "\n",
    "Де:\n",
    "- $ y $ — це справжнє значення (мітка класу, 0 або 1).\n",
    "- $ \\hat{y} $ — це передбачене значення (ймовірність).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GtOYB-RHfc_r"
   },
   "source": [
    "1.\n",
    "Тут вже наведений код для ініціювання набору даних в форматі numpy. Перетворіть `inputs`, `targets` на `torch` тензори. Виведіть результат на екран."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T15:33:51.673372Z",
     "start_time": "2025-11-01T15:33:50.913993Z"
    },
    "id": "3BNXSR-VdYKQ"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T15:33:52.677335Z",
     "start_time": "2025-11-01T15:33:52.671777Z"
    },
    "id": "QLKZ77x4v_-v"
   },
   "outputs": [],
   "source": [
    "# Вхідні дані (temp, rainfall, humidity)\n",
    "inputs = np.array([[73, 67, 43],\n",
    "                   [91, 88, 64],\n",
    "                   [87, 134, 58],\n",
    "                   [102, 43, 37],\n",
    "                   [69, 96, 70]], dtype='float32')\n",
    "\n",
    "# Таргети (apples > 80)\n",
    "targets = np.array([[0],\n",
    "                    [1],\n",
    "                    [1],\n",
    "                    [0],\n",
    "                    [1]], dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T15:33:54.632561Z",
     "start_time": "2025-11-01T15:33:54.620763Z"
    },
    "id": "KjoeaDrk6fO7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вхідні дані:\n",
      " tensor([[ 73.,  67.,  43.],\n",
      "        [ 91.,  88.,  64.],\n",
      "        [ 87., 134.,  58.],\n",
      "        [102.,  43.,  37.],\n",
      "        [ 69.,  96.,  70.]])\n",
      "\n",
      "Мітки:\n",
      " tensor([[0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.]])\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.from_numpy(inputs)\n",
    "targets = torch.from_numpy(targets)\n",
    "\n",
    "print(\"Вхідні дані:\\n\", inputs)\n",
    "print(\"\\nМітки:\\n\", targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iKzbJKfOgGV8"
   },
   "source": [
    "2. Ініціюйте ваги `w`, `b` для моделі логістичної регресії потрібної форми зважаючи на розмірності даних випадковими значеннями з нормального розподілу. Лишаю тут код для фіксації `random_seed`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T15:33:56.046917Z",
     "start_time": "2025-11-01T15:33:56.031435Z"
    },
    "id": "aXhKw6Tdj1-d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1118f3450>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.random.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T15:33:57.290848Z",
     "start_time": "2025-11-01T15:33:57.284670Z"
    },
    "id": "eApcB7eb6h9o"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Початкові ваги:\n",
      " tensor([[0.6614, 0.2669, 0.0617]], requires_grad=True)\n",
      "Початковий bias:\n",
      " tensor([0.6213], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "w = torch.randn(1, 3, requires_grad=True) \n",
    "b = torch.randn(1, requires_grad=True)\n",
    "\n",
    "print(\"Початкові ваги:\\n\", w)\n",
    "print(\"Початковий bias:\\n\", b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nYGxNGTaf5s6"
   },
   "source": [
    "3. Напишіть функцію `model`, яка буде обчислювати функцію гіпотези в логістичній регресії і дозволяти робити передбачення на основі введеного рядка даних і коефіцієнтів в змінних `w`, `b`.\n",
    "\n",
    "  **Важливий момент**, що функція `model` робить обчислення на `torch.tensors`, тож для математичних обчислень використовуємо фукнціонал `torch`, наприклад:\n",
    "  - обчсилення $e^x$: `torch.exp(x)`\n",
    "  - обчсилення $log(x)$: `torch.log(x)`\n",
    "  - обчислення середнього значення вектору `x`: `torch.mean(x)`\n",
    "\n",
    "  Використайте функцію `model` для обчислення передбачень з поточними значеннями `w`, `b`.Виведіть результат обчислень на екран.\n",
    "\n",
    "  Проаналізуйте передбачення. Чи не викликають вони у вас підозр? І якщо викликають, то чим це може бути зумовлено?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T15:34:00.120331Z",
     "start_time": "2025-11-01T15:34:00.114088Z"
    },
    "id": "pSz2j4Fh6jBv"
   },
   "outputs": [],
   "source": [
    "def model(x, w, b):\n",
    "    z = torch.matmul(x, w.T) + b\n",
    "    y_hat = 1 / (1 + torch.exp(-z))\n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T15:34:03.530077Z",
     "start_time": "2025-11-01T15:34:03.522319Z"
    },
    "id": "pSz2j4Fh6jBv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "preds = model(inputs, w, b)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T15:34:05.375399Z",
     "start_time": "2025-11-01T15:34:05.370937Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.]])\n"
     ]
    }
   ],
   "source": [
    "print(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Всі передбачення вийшли рівними 1, тобто модель ніби не розрізняє класи, що вказує на проблему gradient vanishing.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O2AGM0Mb2yHa"
   },
   "source": [
    "4. Напишіть функцію `binary_cross_entropy`, яка приймає на вхід передбачення моделі `predicted_probs` та справжні мітки в даних `true_labels` і обчислює значення втрат (loss)  за формулою бінарної крос-ентропії для кожного екземпляра та вертає середні втрати по всьому набору даних.\n",
    "  Використайте функцію `binary_cross_entropy` для обчислення втрат для поточних передбачень моделі."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T15:34:07.106584Z",
     "start_time": "2025-11-01T15:34:07.101470Z"
    },
    "id": "1bWlovvx6kZS"
   },
   "outputs": [],
   "source": [
    "def binary_cross_entropy(predicted_probs, true_labels):\n",
    "    loss = - (true_labels * torch.log(predicted_probs) +\n",
    "              (1 - true_labels) * torch.log(1 - predicted_probs))\n",
    "    return torch.mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T15:34:08.348662Z",
     "start_time": "2025-11-01T15:34:08.343278Z"
    },
    "id": "1bWlovvx6kZS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Початковий loss: nan\n"
     ]
    }
   ],
   "source": [
    "loss = binary_cross_entropy(preds, targets)\n",
    "print(\"Початковий loss:\", loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZFKpQxdHi1__"
   },
   "source": [
    "5. Зробіть зворотнє поширення помилки і виведіть градієнти за параметрами `w`, `b`. Проаналізуйте їх значення. Як гадаєте, чому вони саме такі?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T15:34:10.040701Z",
     "start_time": "2025-11-01T15:34:09.995396Z"
    },
    "id": "YAbXUNSJ6mCl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Градієнти w:\n",
      " tensor([[nan, nan, nan]])\n",
      "Градієнти b:\n",
      " tensor([nan])\n"
     ]
    }
   ],
   "source": [
    "loss.backward()\n",
    "\n",
    "print(\"Градієнти w:\\n\", w.grad)\n",
    "print(\"Градієнти b:\\n\", b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Якщо loss є nan, то й усі градієнти автоматично стають nan, бо вони обчислюються з похідних від цього nan-значення.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nDN1t1RujQsK"
   },
   "source": [
    "**Що сталось?**\n",
    "\n",
    "В цій задачі, коли ми ініціювали значення випадковими значеннями з нормального розподілу, насправді ці значення не були дуже гарними стартовими значеннями і привели до того, що градієнти стали дуже малими або навіть рівними нулю (це призводить до того, що градієнти \"зникають\"), і відповідно при оновленні ваг у нас не буде нічого змінюватись. Це називається `gradient vanishing`. Це відбувається через **насичення сигмоїдної функції активації.**\n",
    "\n",
    "У нашій задачі ми використовуємо сигмоїдну функцію активації, яка має такий вигляд:\n",
    "\n",
    "   $$\n",
    "   \\sigma(z) = \\frac{1}{1 + e^{-z}}\n",
    "   $$\n",
    "\n",
    "\n",
    "Коли значення $z$ дуже велике або дуже мале, сигмоїдна функція починає \"насичуватись\". Це означає, що для великих позитивних $z$ сигмоїда наближається до 1, а для великих негативних — до 0. В цих діапазонах градієнти починають стрімко зменшуватись і наближаються до нуля (бо градієнт - це похідна, похідна на проміжку функції, де вона паралельна осі ОХ, дорівнює 0), що робить оновлення ваг неможливим.\n",
    "\n",
    "![](https://editor.analyticsvidhya.com/uploads/27889vaegp.png)\n",
    "\n",
    "У логістичній регресії $ z = x \\cdot w + b $. Якщо ваги $w, b$ - великі, значення $z$ також буде великим, і сигмоїда перейде в насичену область, де градієнти дуже малі.\n",
    "\n",
    "Саме це сталося в нашій задачі, де великі випадкові значення ваг викликали насичення сигмоїдної функції. Це в свою чергу призводить до того, що під час зворотного поширення помилки (backpropagation) модель оновлює ваги дуже повільно або зовсім не оновлює. Це називається проблемою **зникнення градієнтів** (gradient vanishing problem).\n",
    "\n",
    "**Що ж робити?**\n",
    "Ініціювати ваги маленькими значеннями навколо нуля. Наприклад ми можемо просто в існуючій ініціалізації ваги розділити на 1000. Можна також використати інший спосіб ініціалізації вагів - інформація про це [тут](https://www.geeksforgeeks.org/initialize-weights-in-pytorch/).\n",
    "\n",
    "Як це робити - показую нижче. **Виконайте код та знову обчисліть передбачення, лосс і виведіть градієнти.**\n",
    "\n",
    "А я пишу пояснення, чому просто не зробити\n",
    "\n",
    "```\n",
    "w = torch.randn(1, 3, requires_grad=True)/1000\n",
    "b = torch.randn(1, requires_grad=True)/1000\n",
    "```\n",
    "\n",
    "Нам потрібно, аби тензори вагів були листовими (leaf tensors).\n",
    "\n",
    "1. **Що таке листовий тензор**\n",
    "Листовий тензор — це тензор, який був створений користувачем безпосередньо і з якого починається обчислювальний граф. Якщо такий тензор має `requires_grad=True`, PyTorch буде відслідковувати всі операції, виконані над ним, щоб правильно обчислювати градієнти під час навчання.\n",
    "\n",
    "2. **Чому ми використовуємо `w.data` замість звичайних операцій**\n",
    "Якщо ми просто виконали б операції, такі як `(w - 0.5) / 100`, ми б отримали **новий тензор**, який вже не був би листовим тензором, оскільки ці операції створюють **новий** тензор, а не модифікують існуючий.\n",
    "\n",
    "  Проте, щоб залишити наші тензори ваги `w` та зміщення `b` листовими і продовжити можливість відстеження градієнтів під час тренування, ми використовуємо атрибут `.data`. Цей атрибут дозволяє **виконувати операції in-place (прямо на існуючому тензорі)** без зміни самого об'єкта тензора. Отже, тензор залишається листовим, і PyTorch може коректно обчислювати його градієнти.\n",
    "\n",
    "3. **Чому важливо залишити тензор листовим**\n",
    "Якщо тензор більше не є листовим (наприклад, через проведення операцій, що створюють нові тензори), ви не зможете отримати градієнти за допомогою `w.grad` чи `b.grad` після виклику `loss.backward()`. Це може призвести до втрати можливості оновлення параметрів під час тренування моделі. В нашому випадку ми хочемо, щоб тензори `w` та `b` накопичували градієнти, тому вони повинні залишатись листовими.\n",
    "\n",
    "**Висновок:**\n",
    "Ми використовуємо `.data`, щоб виконати операції зміни значень на ваги і зміщення **in-place**, залишаючи їх листовими тензорами, які можуть накопичувати градієнти під час навчання. Це дозволяє коректно працювати механізму зворотного поширення помилки (backpropagation) і оновлювати ваги моделі."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rOPSQyttpVjO"
   },
   "source": [
    "5. Виконайте код та знову обчисліть передбачення, лосс і знайдіть градієнти та виведіть всі ці тензори на екран."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T15:34:13.915546Z",
     "start_time": "2025-11-01T15:34:13.908730Z"
    },
    "id": "-EBOJ3tsnRaD"
   },
   "outputs": [],
   "source": [
    "torch.random.manual_seed(1)\n",
    "w = torch.randn(1, 3, requires_grad=True)  # Листовий тензор\n",
    "b = torch.randn(1, requires_grad=True)     # Листовий тензор\n",
    "\n",
    "# in-place операції\n",
    "w.data = w.data / 1000\n",
    "b.data = b.data / 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T15:34:15.250110Z",
     "start_time": "2025-11-01T15:34:15.242987Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Малі ініціалізовані ваги:\n",
      " tensor([[6.6135e-04, 2.6692e-04, 6.1677e-05]], requires_grad=True)\n",
      "Малий bias:\n",
      " tensor([0.0006], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(\"Малі ініціалізовані ваги:\\n\", w)\n",
    "print(\"Малий bias:\\n\", b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T15:34:16.671224Z",
     "start_time": "2025-11-01T15:34:16.661403Z"
    },
    "id": "-JwXiSpX6orh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Передбачення після масштабування ваг:\n",
      " tensor([[0.5174],\n",
      "        [0.5220],\n",
      "        [0.5244],\n",
      "        [0.5204],\n",
      "        [0.5190]], grad_fn=<MulBackward0>)\n",
      "Loss: 0.6829456686973572\n",
      "Градієнти w:\n",
      " tensor([[ -5.4417, -18.9853, -10.0682]])\n",
      "Градієнти b:\n",
      " tensor([-0.0794])\n"
     ]
    }
   ],
   "source": [
    "preds = model(inputs, w, b)\n",
    "loss = binary_cross_entropy(preds, targets)\n",
    "loss.backward()\n",
    "\n",
    "print(\"Передбачення після масштабування ваг:\\n\", preds)\n",
    "print(\"Loss:\", loss.item())\n",
    "print(\"Градієнти w:\\n\", w.grad)\n",
    "print(\"Градієнти b:\\n\", b.grad)\n",
    "\n",
    "# Тепер модель може вчитись"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RCdi44IT334o"
   },
   "source": [
    "6. Напишіть алгоритм градієнтного спуску, який буде навчати модель з використанням написаних раніше функцій і виконуючи оновлення ваг. Алгоритм має включати наступні кроки:\n",
    "\n",
    "  1. Генерація прогнозів\n",
    "  2. Обчислення втрат\n",
    "  3. Обчислення градієнтів (gradients) loss-фукнції відносно ваг і зсувів\n",
    "  4. Налаштування ваг шляхом віднімання невеликої величини, пропорційної градієнту (`learning_rate` домножений на градієнт)\n",
    "  5. Скидання градієнтів на нуль\n",
    "\n",
    "Виконайте градієнтний спуск протягом 1000 епох, обчисліть фінальні передбачення і проаналізуйте, чи вони точні?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T15:34:19.037718Z",
     "start_time": "2025-11-01T15:34:18.893568Z"
    },
    "id": "mObHPyE06qsO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Епоха 0: loss = 0.6829\n",
      "Епоха 100: loss = 0.5619\n",
      "Епоха 200: loss = 0.5066\n",
      "Епоха 300: loss = 0.4646\n",
      "Епоха 400: loss = 0.4324\n",
      "Епоха 500: loss = 0.4071\n",
      "Епоха 600: loss = 0.3869\n",
      "Епоха 700: loss = 0.3705\n",
      "Епоха 800: loss = 0.3569\n",
      "Епоха 900: loss = 0.3454\n",
      "\n",
      "Фінальні передбачення:\n",
      " tensor([[0.5777],\n",
      "        [0.6685],\n",
      "        [0.9113],\n",
      "        [0.1616],\n",
      "        [0.8653]], grad_fn=<MulBackward0>)\n",
      "Справжні значення:\n",
      " tensor([[0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.]])\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-5\n",
    "num_epochs = 1000\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    preds = model(inputs, w, b)\n",
    "    loss = binary_cross_entropy(preds, targets)\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        w -= learning_rate * w.grad\n",
    "        b -= learning_rate * b.grad\n",
    "        w.grad.zero_()\n",
    "        b.grad.zero_()\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Епоха {epoch}: loss = {loss.item():.4f}\")\n",
    "\n",
    "final_preds = model(inputs, w, b)\n",
    "print(\"\\nФінальні передбачення:\\n\", final_preds)\n",
    "print(\"Справжні значення:\\n\", targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nan немає, loss зменшується і передбачення більш-менш коректні, окрім першого випадку.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fuRhlyF9qAia"
   },
   "source": [
    "**Секція 2. Створення лог регресії з використанням функціоналу `torch.nn`.**\n",
    "\n",
    "Давайте повторно реалізуємо ту ж модель, використовуючи деякі вбудовані функції та класи з PyTorch.\n",
    "\n",
    "Даних у нас буде побільше - тож, визначаємо нові масиви."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T15:34:23.928013Z",
     "start_time": "2025-11-01T15:34:23.640606Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T15:34:25.456782Z",
     "start_time": "2025-11-01T15:34:25.444494Z"
    },
    "id": "IX8Bhm74rV4M"
   },
   "outputs": [],
   "source": [
    "# Вхідні дані (temp, rainfall, humidity)\n",
    "inputs = np.array([[73, 67, 43],\n",
    "                   [91, 88, 64],\n",
    "                   [87, 134, 58],\n",
    "                   [102, 43, 37],\n",
    "                   [69, 96, 70],\n",
    "                   [73, 67, 43],\n",
    "                   [91, 88, 64],\n",
    "                   [87, 134, 58],\n",
    "                   [102, 43, 37],\n",
    "                   [69, 96, 70],\n",
    "                   [73, 67, 43],\n",
    "                   [91, 88, 64],\n",
    "                   [87, 134, 58],\n",
    "                   [102, 43, 37],\n",
    "                   [69, 96, 70]], dtype='float32')\n",
    "\n",
    "# Таргети (apples > 80)\n",
    "targets = np.array([[0],\n",
    "                    [1],\n",
    "                    [1],\n",
    "                    [0],\n",
    "                    [1],\n",
    "                    [0],\n",
    "                    [1],\n",
    "                    [1],\n",
    "                    [0],\n",
    "                    [1],\n",
    "                    [0],\n",
    "                    [1],\n",
    "                    [1],\n",
    "                    [0],\n",
    "                    [1]], dtype='float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7X2dV30KtAPu"
   },
   "source": [
    "7. Завантажте вхідні дані та мітки в PyTorch тензори та з них створіть датасет, який поєднує вхідні дані з мітками, використовуючи клас `TensorDataset`. Виведіть перші 3 елементи в датасеті.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T15:34:28.654423Z",
     "start_time": "2025-11-01T15:34:28.600234Z"
    },
    "id": "chrvMfBs6vjo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Перші 3 елементи датасету:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[ 73.,  67.,  43.],\n",
       "         [ 91.,  88.,  64.],\n",
       "         [ 87., 134.,  58.]]),\n",
       " tensor([[0.],\n",
       "         [1.],\n",
       "         [1.]]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = torch.from_numpy(inputs)\n",
    "targets = torch.from_numpy(targets)\n",
    "\n",
    "train_ds = TensorDataset(inputs, targets)\n",
    "print(\"Перші 3 елементи датасету:\")\n",
    "train_ds[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4nMFaa8suOd3"
   },
   "source": [
    "8. Визначте data loader з класом **DataLoader** для підготовленого датасету `train_ds`, встановіть розмір батчу на 5 та увімкніть перемішування даних для ефективного навчання моделі. Виведіть перший елемент в дата лоадері."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T15:34:30.934381Z",
     "start_time": "2025-11-01T15:34:30.922517Z"
    },
    "id": "ZCsRo5Mx6wEI"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 73.,  67.,  43.],\n",
       "         [ 91.,  88.,  64.],\n",
       "         [102.,  43.,  37.],\n",
       "         [ 69.,  96.,  70.],\n",
       "         [102.,  43.,  37.]]),\n",
       " tensor([[0.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [0.]]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dl = DataLoader(train_ds, batch_size=5, shuffle=True)\n",
    "xb, yb = next(iter(train_dl))\n",
    "xb, yb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ymcQOo_hum6I"
   },
   "source": [
    "9. Створіть клас `LogReg` для логістичної регресії, наслідуючи модуль `torch.nn.Module` за прикладом в лекції (в частині про FeedForward мережі).\n",
    "\n",
    "  У нас модель складається з лінійної комбінації вхідних значень і застосування фукнції сигмоїда. Тож, нейромережа буде складатись з лінійного шару `nn.Linear` і використання активації `nn.Sigmid`. У створеному класі мають бути реалізовані методи `__init__` з ініціалізацією шарів і метод `forward` для виконання прямого проходу моделі через лінійний шар і функцію активації.\n",
    "\n",
    "  Створіть екземпляр класу `LogReg` в змінній `model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T15:34:33.348407Z",
     "start_time": "2025-11-01T15:34:33.343612Z"
    },
    "id": "EyAwhTBW6xxz"
   },
   "outputs": [],
   "source": [
    "class LogReg(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(3, 1)  \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, xb):\n",
    "        out = self.linear(xb)\n",
    "        out = self.sigmoid(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T15:34:35.009982Z",
     "start_time": "2025-11-01T15:34:35.005261Z"
    },
    "id": "EyAwhTBW6xxz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg(\n",
      "  (linear): Linear(in_features=3, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = LogReg()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RflV7xeVyoJy"
   },
   "source": [
    "10. Задайте оптимізатор `Stockastic Gradient Descent` в змінній `opt` для навчання моделі логістичної регресії. А також визначіть в змінній `loss` функцію втрат `binary_cross_entropy` з модуля `torch.nn.functional` для обчислення втрат моделі. Обчисліть втрати для поточних передбачень і міток, а потім виведіть їх. Зробіть висновок, чи моделі вдалось навчитись?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T15:34:37.673354Z",
     "start_time": "2025-11-01T15:34:37.044520Z"
    },
    "id": "3QCATPU_6yfa"
   },
   "outputs": [],
   "source": [
    "opt = torch.optim.SGD(model.parameters(), 1e-5)\n",
    "loss_fn = F.binary_cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T15:34:38.977492Z",
     "start_time": "2025-11-01T15:34:38.969845Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Передбачення моделі:\n",
      " tensor([[1.7603e-01],\n",
      "        [3.3674e-02],\n",
      "        [9.9996e-01],\n",
      "        [4.3257e-05],\n",
      "        [9.9996e-01]])\n",
      "\n",
      "Мітки:\n",
      " tensor([[0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "\n",
      "Початковий loss: 6.816744327545166\n"
     ]
    }
   ],
   "source": [
    "preds = model(xb)\n",
    "loss = loss_fn(preds, yb)\n",
    "\n",
    "print(\"Передбачення моделі:\\n\", preds.detach())\n",
    "print(\"\\nМітки:\\n\", yb)\n",
    "print(\"\\nПочатковий loss:\", loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**На цьому етапі точність моделі ще дуже низька, а loss є великим. Модель потрібно навчити, щоб втрати зменшилися і передбачення стали точнішими.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ch-WrYnKzMzq"
   },
   "source": [
    "11. Візьміть з лекції функцію для тренування моделі з відстеженням значень втрат і навчіть щойно визначену модель на 1000 епохах. Виведіть після цього графік зміни loss, фінальні передбачення і значення таргетів."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T15:35:11.792014Z",
     "start_time": "2025-11-01T15:35:11.774068Z"
    },
    "id": "cEHQH9qE626k"
   },
   "outputs": [],
   "source": [
    "def fit_return_loss(num_epochs, model, loss_fn, opt, train_dl):\n",
    "    losses = []\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0  \n",
    "\n",
    "        for xb, yb in train_dl:\n",
    "            preds = model(xb)\n",
    "            loss = loss_fn(preds, yb)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "        avg_loss = total_loss / len(train_dl)\n",
    "        losses.append(avg_loss)\n",
    "\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f\"Епоха [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T15:35:14.168863Z",
     "start_time": "2025-11-01T15:35:13.760839Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Епоха [10/1000], Loss: 6.6400\n",
      "Епоха [20/1000], Loss: 6.0483\n",
      "Епоха [30/1000], Loss: 5.7263\n",
      "Епоха [40/1000], Loss: 5.4710\n",
      "Епоха [50/1000], Loss: 5.2474\n",
      "Епоха [60/1000], Loss: 5.0653\n",
      "Епоха [70/1000], Loss: 4.8974\n",
      "Епоха [80/1000], Loss: 4.7861\n",
      "Епоха [90/1000], Loss: 4.6903\n",
      "Епоха [100/1000], Loss: 4.5353\n",
      "Епоха [110/1000], Loss: 4.4753\n",
      "Епоха [120/1000], Loss: 4.3686\n",
      "Епоха [130/1000], Loss: 4.2792\n",
      "Епоха [140/1000], Loss: 4.2018\n",
      "Епоха [150/1000], Loss: 4.1132\n",
      "Епоха [160/1000], Loss: 4.0389\n",
      "Епоха [170/1000], Loss: 3.9423\n",
      "Епоха [180/1000], Loss: 3.8701\n",
      "Епоха [190/1000], Loss: 3.7756\n",
      "Епоха [200/1000], Loss: 3.6974\n",
      "Епоха [210/1000], Loss: 3.6101\n",
      "Епоха [220/1000], Loss: 3.5297\n",
      "Епоха [230/1000], Loss: 3.4427\n",
      "Епоха [240/1000], Loss: 3.3760\n",
      "Епоха [250/1000], Loss: 3.2822\n",
      "Епоха [260/1000], Loss: 3.1985\n",
      "Епоха [270/1000], Loss: 3.1111\n",
      "Епоха [280/1000], Loss: 3.0308\n",
      "Епоха [290/1000], Loss: 2.9483\n",
      "Епоха [300/1000], Loss: 2.8748\n",
      "Епоха [310/1000], Loss: 2.7879\n",
      "Епоха [320/1000], Loss: 2.7048\n",
      "Епоха [330/1000], Loss: 2.6292\n",
      "Епоха [340/1000], Loss: 2.5456\n",
      "Епоха [350/1000], Loss: 2.4710\n",
      "Епоха [360/1000], Loss: 2.4122\n",
      "Епоха [370/1000], Loss: 2.3102\n",
      "Епоха [380/1000], Loss: 2.2363\n",
      "Епоха [390/1000], Loss: 2.1587\n",
      "Епоха [400/1000], Loss: 2.0854\n",
      "Епоха [410/1000], Loss: 2.0062\n",
      "Епоха [420/1000], Loss: 1.9342\n",
      "Епоха [430/1000], Loss: 1.8632\n",
      "Епоха [440/1000], Loss: 1.7922\n",
      "Епоха [450/1000], Loss: 1.7232\n",
      "Епоха [460/1000], Loss: 1.6485\n",
      "Епоха [470/1000], Loss: 1.5853\n",
      "Епоха [480/1000], Loss: 1.5150\n",
      "Епоха [490/1000], Loss: 1.4520\n",
      "Епоха [500/1000], Loss: 1.3831\n",
      "Епоха [510/1000], Loss: 1.3171\n",
      "Епоха [520/1000], Loss: 1.2595\n",
      "Епоха [530/1000], Loss: 1.2084\n",
      "Епоха [540/1000], Loss: 1.1388\n",
      "Епоха [550/1000], Loss: 1.0851\n",
      "Епоха [560/1000], Loss: 1.0415\n",
      "Епоха [570/1000], Loss: 0.9843\n",
      "Епоха [580/1000], Loss: 0.9393\n",
      "Епоха [590/1000], Loss: 0.8865\n",
      "Епоха [600/1000], Loss: 0.8436\n",
      "Епоха [610/1000], Loss: 0.8030\n",
      "Епоха [620/1000], Loss: 0.7632\n",
      "Епоха [630/1000], Loss: 0.7308\n",
      "Епоха [640/1000], Loss: 0.7033\n",
      "Епоха [650/1000], Loss: 0.6679\n",
      "Епоха [660/1000], Loss: 0.6437\n",
      "Епоха [670/1000], Loss: 0.6134\n",
      "Епоха [680/1000], Loss: 0.5918\n",
      "Епоха [690/1000], Loss: 0.5703\n",
      "Епоха [700/1000], Loss: 0.5492\n",
      "Епоха [710/1000], Loss: 0.5325\n",
      "Епоха [720/1000], Loss: 0.5149\n",
      "Епоха [730/1000], Loss: 0.5012\n",
      "Епоха [740/1000], Loss: 0.4870\n",
      "Епоха [750/1000], Loss: 0.4743\n",
      "Епоха [760/1000], Loss: 0.4654\n",
      "Епоха [770/1000], Loss: 0.4552\n",
      "Епоха [780/1000], Loss: 0.4421\n",
      "Епоха [790/1000], Loss: 0.4315\n",
      "Епоха [800/1000], Loss: 0.4263\n",
      "Епоха [810/1000], Loss: 0.4149\n",
      "Епоха [820/1000], Loss: 0.4085\n",
      "Епоха [830/1000], Loss: 0.4013\n",
      "Епоха [840/1000], Loss: 0.3940\n",
      "Епоха [850/1000], Loss: 0.3883\n",
      "Епоха [860/1000], Loss: 0.3829\n",
      "Епоха [870/1000], Loss: 0.3770\n",
      "Епоха [880/1000], Loss: 0.3719\n",
      "Епоха [890/1000], Loss: 0.3672\n",
      "Епоха [900/1000], Loss: 0.3627\n",
      "Епоха [910/1000], Loss: 0.3587\n",
      "Епоха [920/1000], Loss: 0.3549\n",
      "Епоха [930/1000], Loss: 0.3522\n",
      "Епоха [940/1000], Loss: 0.3474\n",
      "Епоха [950/1000], Loss: 0.3445\n",
      "Епоха [960/1000], Loss: 0.3411\n",
      "Епоха [970/1000], Loss: 0.3395\n",
      "Епоха [980/1000], Loss: 0.3350\n",
      "Епоха [990/1000], Loss: 0.3319\n",
      "Епоха [1000/1000], Loss: 0.3297\n"
     ]
    }
   ],
   "source": [
    "losses = fit_return_loss(1000, model, loss_fn, opt, train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T15:35:19.493920Z",
     "start_time": "2025-11-01T15:35:19.386669Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Фінальні передбачення:\n",
      " tensor([[0.5729],\n",
      "        [0.6791],\n",
      "        [0.9026],\n",
      "        [0.1569],\n",
      "        [0.8761],\n",
      "        [0.5729],\n",
      "        [0.6791],\n",
      "        [0.9026],\n",
      "        [0.1569],\n",
      "        [0.8761],\n",
      "        [0.5729],\n",
      "        [0.6791],\n",
      "        [0.9026],\n",
      "        [0.1569],\n",
      "        [0.8761]])\n",
      "Справжні мітки:\n",
      " tensor([[0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.]])\n"
     ]
    }
   ],
   "source": [
    "plt.plot(losses)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()\n",
    "\n",
    "final_preds = model(inputs)\n",
    "print(\"Фінальні передбачення:\\n\", final_preds.detach())\n",
    "print(\"Справжні мітки:\\n\", targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Під час навчання логістичної регресії loss поступово зменшився до ~0.33. Передбачення доволі добре корелюють із цільовими мітками, хоча результати ніби можна ще покращити.**"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
